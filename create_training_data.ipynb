{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. LOAD virtual environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# terminal command - create .venv file with python==3.10\n",
    "python3.10 -m venv .venv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# terminal command - activate .venv\n",
    "source .venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# terminal command - isntall requirements txt\n",
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. CREATE images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time \n",
    "import uuid # naming image files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = \"Tensorflow/workspace/images/collectedimages\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- UPDATE labels = sign language glosses -**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the labels = sign language glosses the model will be trained\n",
    "labels = [\n",
    "    # sample images already existing\n",
    "    # \"hello\", \"thanks\", \"yes\", \"no\", \"iloveyou\", \n",
    "    # test sentence glosses PHOENIX WEATHER 1May_2010_Saturday_tagesschau_default-11 1 signer05 0.0 1.79769e+308\n",
    "    \"montag\", \"auch\", \"mehr\", \"wolke\", \"als\", \"sonne\", \"ueberwiegend\", \"regen\", \"gewitter\",\n",
    "    ]\n",
    "\n",
    "number_imgs = 15 # 15 per gloss taken -> later transformatoins increase training data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting images for gewitter\n"
     ]
    }
   ],
   "source": [
    "# collect images via webcam\n",
    "for label in labels:\n",
    "    # os.makedirs(\"Tensorflow/workspace/images/collectedimages/\", exist_ok=True) --> already existing with examples of labeled images\n",
    "    cap = cv2.VideoCapture(0) # device number might vary depending on hardware, 0 works for macos\n",
    "    print(\"collecting images for {}\".format(label))\n",
    "    time.sleep(5) # 5s time lapse before starting image collection \n",
    "    for imgnum in range (number_imgs):\n",
    "        ret, frame = cap.read()\n",
    "        imagename = os.path.join(IMAGES_PATH, f\"{label}.{uuid.uuid1()}.jpg\")\n",
    "        # imagename = os.path.join(IMAGES_PATH, label, label+\".\"+\"{}.jpg\".format(str(uuid.uuid1()))) --> old naming used with subfolder structure\n",
    "        cv2.imwrite(imagename, frame)\n",
    "        cv2.imshow(\"frame\", frame)\n",
    "        time.sleep(2)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()  # Close all windows created by cv2.imshow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**- UPDATE canvas.py before running labelimg -**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated .venv/lib/python3.10/site-packages/libs/canvas.py successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def update_canvas_file(file_path):\n",
    "    # Lines to be commented out and their replacements\n",
    "    original_lines = {\n",
    "        526: \"p.drawRect(left_top.x(), left_top.y(), rect_width, rect_height)\",\n",
    "        530: \"p.drawLine(self.prev_point.x(), 0, self.prev_point.x(), self.pixmap.height())\",\n",
    "        531: \"p.drawLine(0, self.prev_point.y(), self.pixmap.width(), self.prev_point.y())\"\n",
    "    }\n",
    "    replacement_lines = {\n",
    "        526: \"p.drawRect(int(left_top.x()), int(left_top.y()), int(rect_width), int(rect_height))\",\n",
    "        530: \"p.drawLine(int(self.prev_point.x()), 0, int(self.prev_point.x()), self.pixmap.height())\",\n",
    "        531: \"p.drawLine(0, int(self.prev_point.y()), self.pixmap.width(), int(self.prev_point.y()))\"\n",
    "    }\n",
    "    \n",
    "    # Read the file\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # Update the lines\n",
    "    for line_num in sorted(original_lines.keys(), reverse=True):\n",
    "        original_line = original_lines[line_num]\n",
    "        if original_line.strip() in lines[line_num - 1].strip():\n",
    "            indent_level = len(lines[line_num - 1]) - len(lines[line_num - 1].lstrip())\n",
    "            lines[line_num - 1] = f\"# {lines[line_num - 1]}\"\n",
    "            lines.insert(line_num, \" \" * indent_level + f\"{replacement_lines[line_num]}\\n\")\n",
    "\n",
    "    # Write the updated lines back to the file\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.writelines(lines)\n",
    "\n",
    "# Path to the canvas.py file\n",
    "file_path = '.venv/lib/python3.10/site-packages/libs/canvas.py'\n",
    "\n",
    "# Update the canvas.py file\n",
    "update_canvas_file(file_path)\n",
    "print(f\"Updated {file_path} successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-03 13:00:49.088 Python[54202:882368] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maximilianscheel/neuefische/capstone_project/capstone_sl_txt_voice/sl_rtod/.venv/lib/python3.10/site-packages/libs/canvas.py\", line 530, in paintEvent\n",
      "    p.drawLine(self.prev_point.x(), 0, self.prev_point.x(), self.pixmap.height())\n",
      "TypeError: arguments did not match any overloaded call:\n",
      "  drawLine(self, l: QLineF): argument 1 has unexpected type 'float'\n",
      "  drawLine(self, line: QLine): argument 1 has unexpected type 'float'\n",
      "  drawLine(self, x1: int, y1: int, x2: int, y2: int): argument 1 has unexpected type 'float'\n",
      "  drawLine(self, p1: QPoint, p2: QPoint): argument 1 has unexpected type 'float'\n",
      "  drawLine(self, p1: Union[QPointF, QPoint], p2: Union[QPointF, QPoint]): argument 1 has unexpected type 'float'\n"
     ]
    }
   ],
   "source": [
    "# install & launch labelimg to label images - create boxes around hand signs in images\n",
    "!labelimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. TRANSFORM dataset (did not improve model)\n",
    "\n",
    "Code snippets create further training material based on created images (e.g. fklipping, cropping, removing background,etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flio_horizontal (mirror)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Define the paths where original images are stored and where flipped images will be saved\n",
    "ORIGINAL_IMAGES_PATH = \"tensorflow/workspace/images/collectedimages\"\n",
    "FLIPPED_IMAGES_PATH = \"tensorflow/workspace/images/transformed_images/flip_horizontal\"\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(FLIPPED_IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "# Function to flip image horizontally and save flipped image with updated XML\n",
    "def flip_image_and_xml(image_path, xml_path, label):\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    flipped_image = cv2.flip(image, 1)  # Horizontal flip\n",
    "    \n",
    "    # Save flipped image\n",
    "    base_filename = os.path.basename(image_path)\n",
    "    flipped_image_name = base_filename.replace(label, f\"{label}.flip\")\n",
    "    flipped_image_path = os.path.join(FLIPPED_IMAGES_PATH, flipped_image_name)\n",
    "    cv2.imwrite(flipped_image_path, flipped_image)\n",
    "    \n",
    "    # Parse XML\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # Update XML filename and path\n",
    "    root.find('filename').text = flipped_image_name\n",
    "    root.find('path').text = flipped_image_path\n",
    "    \n",
    "    # Get image dimensions\n",
    "    width = int(root.find('size/width').text)\n",
    "    \n",
    "    # Adjust bounding boxes\n",
    "    for obj in root.findall('object'):\n",
    "        bndbox = obj.find('bndbox')\n",
    "        xmin = int(bndbox.find('xmin').text)\n",
    "        xmax = int(bndbox.find('xmax').text)\n",
    "        \n",
    "        # Flip bounding box horizontally\n",
    "        new_xmin = width - xmax\n",
    "        new_xmax = width - xmin\n",
    "        \n",
    "        bndbox.find('xmin').text = str(new_xmin)\n",
    "        bndbox.find('xmax').text = str(new_xmax)\n",
    "    \n",
    "    # Save updated XML\n",
    "    flipped_xml_path = os.path.join(FLIPPED_IMAGES_PATH, flipped_image_name.replace('.jpg', '.xml'))\n",
    "    tree.write(flipped_xml_path)\n",
    "\n",
    "# Loop through original images and XML files\n",
    "for filename in os.listdir(ORIGINAL_IMAGES_PATH):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        label = filename.split('.')[0]\n",
    "        image_path = os.path.join(ORIGINAL_IMAGES_PATH, filename)\n",
    "        xml_path = image_path.replace(\".jpg\", \".xml\")\n",
    "        \n",
    "        if os.path.exists(xml_path):\n",
    "            flip_image_and_xml(image_path, xml_path, label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random_rotate (not used as position/ rotation of hand might distort meaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import xml.etree.ElementTree as ET\n",
    "import random\n",
    "\n",
    "# Define the path where original images are stored and where rotated images will be saved\n",
    "ORIGINAL_IMAGES_PATH = \"tensorflow/workspace/images/collectedimages\"\n",
    "ROTATED_IMAGES_PATH = \"tensorflow/workspace/images/transformed_images/random_rotate\"\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(ROTATED_IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "# Function to rotate image and save rotated image with updated XML\n",
    "def rotate_image_and_xml(image_path, xml_path, label):\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # Generate a random angle between -30 and 30 degrees\n",
    "    angle = random.uniform(-30, 30)\n",
    "    center = (width / 2, height / 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "\n",
    "    # Compute the size of the rotated image\n",
    "    cos = abs(M[0, 0])\n",
    "    sin = abs(M[0, 1])\n",
    "    new_width = int((height * sin) + (width * cos))\n",
    "    new_height = int((height * cos) + (width * sin))\n",
    "\n",
    "    # Adjust the rotation matrix to take into account translation\n",
    "    M[0, 2] += (new_width / 2) - center[0]\n",
    "    M[1, 2] += (new_height / 2) - center[1]\n",
    "\n",
    "    # Perform the rotation\n",
    "    rotated_image = cv2.warpAffine(image, M, (new_width, new_height))\n",
    "\n",
    "    # Save rotated image\n",
    "    base_filename = os.path.basename(image_path)\n",
    "    rotated_image_name = base_filename.replace(label, f\"{label}.rotate\")\n",
    "    rotated_image_path = os.path.join(ROTATED_IMAGES_PATH, rotated_image_name)\n",
    "    cv2.imwrite(rotated_image_path, rotated_image)\n",
    "\n",
    "    # Parse XML\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    # Update XML filename and path\n",
    "    root.find('filename').text = rotated_image_name\n",
    "    root.find('path').text = rotated_image_path\n",
    "\n",
    "    # Adjust bounding boxes\n",
    "    for obj in root.findall('object'):\n",
    "        bndbox = obj.find('bndbox')\n",
    "        xmin = int(bndbox.find('xmin').text)\n",
    "        ymin = int(bndbox.find('ymin').text)\n",
    "        xmax = int(bndbox.find('xmax').text)\n",
    "        ymax = int(bndbox.find('ymax').text)\n",
    "\n",
    "        # Coordinates of the four corners of the bounding box\n",
    "        corners = [\n",
    "            [xmin, ymin],\n",
    "            [xmax, ymin],\n",
    "            [xmax, ymax],\n",
    "            [xmin, ymax]\n",
    "        ]\n",
    "\n",
    "        # Rotate the corners\n",
    "        rotated_corners = []\n",
    "        for corner in corners:\n",
    "            x, y = corner\n",
    "            new_x = M[0, 0] * x + M[0, 1] * y + M[0, 2]\n",
    "            new_y = M[1, 0] * x + M[1, 1] * y + M[1, 2]\n",
    "            rotated_corners.append([new_x, new_y])\n",
    "\n",
    "        # Find the new bounding box\n",
    "        new_xmin = min(corner[0] for corner in rotated_corners)\n",
    "        new_ymin = min(corner[1] for corner in rotated_corners)\n",
    "        new_xmax = max(corner[0] for corner in rotated_corners)\n",
    "        new_ymax = max(corner[1] for corner in rotated_corners)\n",
    "\n",
    "        # Ensure the bounding box is within the image boundaries\n",
    "        new_xmin = max(0, new_xmin)\n",
    "        new_ymin = max(0, new_ymin)\n",
    "        new_xmax = min(new_width, new_xmax)\n",
    "        new_ymax = min(new_height, new_ymax)\n",
    "\n",
    "        bndbox.find('xmin').text = str(int(new_xmin))\n",
    "        bndbox.find('ymin').text = str(int(new_ymin))\n",
    "        bndbox.find('xmax').text = str(int(new_xmax))\n",
    "        bndbox.find('ymax').text = str(int(new_ymax))\n",
    "\n",
    "    # Save updated XML\n",
    "    rotated_xml_path = os.path.join(ROTATED_IMAGES_PATH, rotated_image_name.replace('.jpg', '.xml'))\n",
    "    tree.write(rotated_xml_path)\n",
    "\n",
    "# Loop through original images and XML files\n",
    "for filename in os.listdir(ORIGINAL_IMAGES_PATH):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        label = filename.split('.')[0]\n",
    "        image_path = os.path.join(ORIGINAL_IMAGES_PATH, filename)\n",
    "        xml_path = image_path.replace(\".jpg\", \".xml\")\n",
    "\n",
    "        if os.path.exists(xml_path):\n",
    "            rotate_image_and_xml(image_path, xml_path, label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## crop_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "import random\n",
    "\n",
    "# Define the path where original images are stored and where cropped images will be saved\n",
    "ORIGINAL_IMAGES_PATH = \"tensorflow/workspace/images/collectedimages\"\n",
    "CROPPED_IMAGES_PATH = \"tensorflow/workspace/images/transformed_images/crop_random\"\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(CROPPED_IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "# Function to randomly crop image and save cropped image with updated XML\n",
    "def crop_image_and_xml(image_path, xml_path, label):\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # Parse XML\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # Get bounding box\n",
    "    bndbox = root.find('object/bndbox')\n",
    "    xmin = int(bndbox.find('xmin').text)\n",
    "    ymin = int(bndbox.find('ymin').text)\n",
    "    xmax = int(bndbox.find('xmax').text)\n",
    "    ymax = int(bndbox.find('ymax').text)\n",
    "\n",
    "    # Calculate the range for random cropping ensuring the bounding box stays within the cropped image\n",
    "    crop_x_min = max(0, xmin - random.randint(0, xmin))\n",
    "    crop_y_min = max(0, ymin - random.randint(0, ymin))\n",
    "    crop_x_max = min(width, xmax + random.randint(0, width - xmax))\n",
    "    crop_y_max = min(height, ymax + random.randint(0, height - ymax))\n",
    "\n",
    "    cropped_image = image[crop_y_min:crop_y_max, crop_x_min:crop_x_max]\n",
    "    cropped_height, cropped_width = cropped_image.shape[:2]\n",
    "\n",
    "    # Save cropped image\n",
    "    base_filename = os.path.basename(image_path)\n",
    "    cropped_image_name = base_filename.replace(label, f\"{label}.crop\")\n",
    "    cropped_image_path = os.path.join(CROPPED_IMAGES_PATH, cropped_image_name)\n",
    "    cv2.imwrite(cropped_image_path, cropped_image)\n",
    "\n",
    "    # Update XML filename and path\n",
    "    root.find('filename').text = cropped_image_name\n",
    "    root.find('path').text = cropped_image_path\n",
    "\n",
    "    # Adjust bounding box to match the cropped image\n",
    "    new_xmin = xmin - crop_x_min\n",
    "    new_ymin = ymin - crop_y_min\n",
    "    new_xmax = xmax - crop_x_min\n",
    "    new_ymax = ymax - crop_y_min\n",
    "\n",
    "    bndbox.find('xmin').text = str(new_xmin)\n",
    "    bndbox.find('ymin').text = str(new_ymin)\n",
    "    bndbox.find('xmax').text = str(new_xmax)\n",
    "    bndbox.find('ymax').text = str(new_ymax)\n",
    "\n",
    "    # Save updated XML\n",
    "    cropped_xml_path = os.path.join(CROPPED_IMAGES_PATH, cropped_image_name.replace('.jpg', '.xml'))\n",
    "    tree.write(cropped_xml_path)\n",
    "\n",
    "# Loop through original images and XML files\n",
    "for filename in os.listdir(ORIGINAL_IMAGES_PATH):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        label = filename.split('.')[0]\n",
    "        image_path = os.path.join(ORIGINAL_IMAGES_PATH, filename)\n",
    "        xml_path = image_path.replace(\".jpg\", \".xml\")\n",
    "        \n",
    "        if os.path.exists(xml_path):\n",
    "            crop_image_and_xml(image_path, xml_path, label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove_background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Define the path where original images are stored and where the transformed images will be saved\n",
    "ORIGINAL_IMAGES_PATH = \"tensorflow/workspace/images/collectedimages\"\n",
    "BACKGROUND_REMOVED_IMAGES_PATH = \"tensorflow/workspace/images/transformed_images/remove_background\"\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(BACKGROUND_REMOVED_IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "# Function to remove background and save image with updated XML\n",
    "def remove_background_and_xml(image_path, xml_path, label):\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # Parse XML\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # Get bounding box\n",
    "    bndbox = root.find('object/bndbox')\n",
    "    xmin = int(bndbox.find('xmin').text)\n",
    "    ymin = int(bndbox.find('ymin').text)\n",
    "    xmax = int(bndbox.find('xmax').text)\n",
    "    ymax = int(bndbox.find('ymax').text)\n",
    "\n",
    "    # Create a mask for the bounding box\n",
    "    mask = np.zeros((height, width), dtype=np.uint8)\n",
    "    mask[ymin:ymax, xmin:xmax] = 255\n",
    "\n",
    "    # Apply the mask to the image\n",
    "    result = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    # Save the result image\n",
    "    base_filename = os.path.basename(image_path)\n",
    "    background_removed_image_name = base_filename.replace(label, f\"{label}.bg_removed\")\n",
    "    background_removed_image_path = os.path.join(BACKGROUND_REMOVED_IMAGES_PATH, background_removed_image_name)\n",
    "    cv2.imwrite(background_removed_image_path, result)\n",
    "\n",
    "    # Update XML filename and path\n",
    "    root.find('filename').text = background_removed_image_name\n",
    "    root.find('path').text = background_removed_image_path\n",
    "\n",
    "    # Save updated XML\n",
    "    background_removed_xml_path = os.path.join(BACKGROUND_REMOVED_IMAGES_PATH, background_removed_image_name.replace('.jpg', '.xml'))\n",
    "    tree.write(background_removed_xml_path)\n",
    "\n",
    "# Loop through original images and XML files\n",
    "for filename in os.listdir(ORIGINAL_IMAGES_PATH):\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        label = filename.split('.')[0]\n",
    "        image_path = os.path.join(ORIGINAL_IMAGES_PATH, filename)\n",
    "        xml_path = image_path.replace(\".jpg\", \".xml\")\n",
    "        \n",
    "        if os.path.exists(xml_path):\n",
    "            remove_background_and_xml(image_path, xml_path, label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. SPLIT collectedimages dataset into train 80 % & test 20%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 COPY transformed images to collectedimages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy all images from images/transformed_images subfolders to images/collectedimages\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define the source and destination directories\n",
    "SOURCE_DIR = \"tensorflow/workspace/images/transformed_images\"\n",
    "DESTINATION_DIR = \"tensorflow/workspace/images/collectedimages\"\n",
    "\n",
    "# Ensure the destination directory exists\n",
    "os.makedirs(DESTINATION_DIR, exist_ok=True)\n",
    "\n",
    "# Function to copy all files from source subfolders to the destination directory\n",
    "def copy_files_to_collectedimages(source_dir, dest_dir):\n",
    "    for root, dirs, files in os.walk(source_dir):\n",
    "        for file in files:\n",
    "            source_file = os.path.join(root, file)\n",
    "            dest_file = os.path.join(dest_dir, file)\n",
    "            shutil.copy2(source_file, dest_file)\n",
    "\n",
    "# Copy all files from the transformed_images subfolders to collectedimages\n",
    "copy_files_to_collectedimages(SOURCE_DIR, DESTINATION_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 SPLITTING data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and test datasets created. 108 images in the train set and 27 images in the test set.\n"
     ]
    }
   ],
   "source": [
    "# split images/collectedimages into train 80% vs test 20%\n",
    "\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import math\n",
    "\n",
    "# Define paths\n",
    "IMAGES_PATH = \"Tensorflow/workspace/images/collectedimages\"\n",
    "TRAIN_PATH = \"Tensorflow/workspace/images/train\"\n",
    "TEST_PATH = \"Tensorflow/workspace/images/test\"\n",
    "\n",
    "# Ensure train and test directories exist\n",
    "os.makedirs(TRAIN_PATH, exist_ok=True)\n",
    "os.makedirs(TEST_PATH, exist_ok=True)\n",
    "\n",
    "# Get list of all image files\n",
    "files = [f for f in os.listdir(IMAGES_PATH) if f.endswith('.jpg')]\n",
    "\n",
    "# Group files by label\n",
    "label_dict = {}\n",
    "for file in files:\n",
    "    label = file.split('.')[0]\n",
    "    if label not in label_dict:\n",
    "        label_dict[label] = []\n",
    "    label_dict[label].append(file)\n",
    "\n",
    "# Shuffle and split files by label\n",
    "train_files = []\n",
    "test_files = []\n",
    "\n",
    "for label, file_list in label_dict.items():\n",
    "    random.shuffle(file_list)\n",
    "    num_train = math.floor(len(file_list) * 0.8)\n",
    "    train_files.extend(file_list[:num_train])\n",
    "    test_files.extend(file_list[num_train:])\n",
    "\n",
    "# Function to copy files to their respective directories\n",
    "def copy_files(file_list, destination_path):\n",
    "    for file in file_list:\n",
    "        base_filename = os.path.splitext(file)[0]\n",
    "        # Copy image file\n",
    "        shutil.copy(os.path.join(IMAGES_PATH, file), destination_path)\n",
    "        # Copy corresponding XML file\n",
    "        shutil.copy(os.path.join(IMAGES_PATH, base_filename + '.xml'), destination_path)\n",
    "\n",
    "# Copy train files\n",
    "copy_files(train_files, TRAIN_PATH)\n",
    "\n",
    "# Copy test files\n",
    "copy_files(test_files, TEST_PATH)\n",
    "\n",
    "print(f\"Train and test datasets created. {len(train_files)} images in the train set and {len(test_files)} images in the test set.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
