{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD virtual environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create virtual environment\n",
    "!python3.10 -m venv .venv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activate vitual environment\n",
    "!source .venv/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install modules required\n",
    "pip install -r streamlit_requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import time \n",
    "import uuid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = \"Tensorflow/workspace/images/collectedimages\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the labels = sign language glosses the model shall detect\n",
    "labels = [\n",
    "    # test glosses from PHOENIX weather file 1May_2010_Saturday_tagesschau_default-11 1 signer05 0.0 1.79769e+308\n",
    "    \"montag\", \"auch\", \"mehr\", \"wolke\", \"als\", \"sonne\", \"ueberwiegend\", \"regen\", \"gewitter\",\n",
    "    ]\n",
    "\n",
    "number_imgs = 15 # suffices for detecting glosses in similar environment, but is not sufficient for robust model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take 15 images per gloss sequentially via webcam\n",
    "for label in labels:\n",
    "    os.makedirs(\"Tensorflow/workspace/images/collectedimages/\", exist_ok=True) # create folder collectedimages\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    print(\"collecting images for {}\".format(label))\n",
    "    time.sleep(5) # 5s time lapse before starting collection of glosses\n",
    "    for imgnum in range (number_imgs):\n",
    "        ret, frame = cap.read()\n",
    "        imagename = os.path.join(IMAGES_PATH, f\"{label}.{uuid.uuid1()}.jpg\")\n",
    "        cv2.imwrite(imagename, frame)\n",
    "        cv2.imshow(\"frame\", frame)\n",
    "        time.sleep(2)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated ../.venv/lib/python3.10/site-packages/libs/canvas.py successfully.\n"
     ]
    }
   ],
   "source": [
    "# update canvas.py toe ensure react boxes can be drawn with labelimg\n",
    "import os\n",
    "\n",
    "def update_canvas_file(file_path):\n",
    "    original_lines = {\n",
    "        526: \"p.drawRect(left_top.x(), left_top.y(), rect_width, rect_height)\",\n",
    "        530: \"p.drawLine(self.prev_point.x(), 0, self.prev_point.x(), self.pixmap.height())\",\n",
    "        531: \"p.drawLine(0, self.prev_point.y(), self.pixmap.width(), self.prev_point.y())\"\n",
    "    }\n",
    "    replacement_lines = {\n",
    "        526: \"p.drawRect(int(left_top.x()), int(left_top.y()), int(rect_width), int(rect_height))\",\n",
    "        530: \"p.drawLine(int(self.prev_point.x()), 0, int(self.prev_point.x()), self.pixmap.height())\",\n",
    "        531: \"p.drawLine(0, int(self.prev_point.y()), self.pixmap.width(), int(self.prev_point.y()))\"\n",
    "    }\n",
    "    \n",
    "    # Read the file\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    # Update the lines\n",
    "    for line_num in sorted(original_lines.keys(), reverse=True):\n",
    "        original_line = original_lines[line_num]\n",
    "        if original_line.strip() in lines[line_num - 1].strip():\n",
    "            indent_level = len(lines[line_num - 1]) - len(lines[line_num - 1].lstrip())\n",
    "            lines[line_num - 1] = f\"# {lines[line_num - 1]}\"\n",
    "            lines.insert(line_num, \" \" * indent_level + f\"{replacement_lines[line_num]}\\n\")\n",
    "\n",
    "    # Write the updated lines back to the file\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.writelines(lines)\n",
    "\n",
    "# Path to the canvas.py file\n",
    "file_path = '../.venv/lib/python3.10/site-packages/libs/canvas.py'\n",
    "\n",
    "# Update the canvas.py file\n",
    "update_canvas_file(file_path)\n",
    "print(f\"Updated {file_path} successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-07 21:25:43.895 Python[23038:620452] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/maximilianscheel/neuefische/capstone_project/sign2voice_rtod/.venv/lib/python3.10/site-packages/labelImg/labelImg.py\", line 965, in scroll_request\n",
      "    bar.setValue(bar.value() + bar.singleStep() * units)\n",
      "TypeError: setValue(self, a0: int): argument 1 has unexpected type 'float'\n"
     ]
    }
   ],
   "source": [
    "# launch labelimg to create bounding boxes and assign classes = sign language gloss to be detected\n",
    "!labelimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLIT collectedimages dataset into train 80 % & test 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and test datasets created. 108 images in the train set and 27 images in the test set.\n"
     ]
    }
   ],
   "source": [
    "# split folder tensorflow/workpace/images/collectedimages into train 80% vs test 20%\n",
    "\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import math\n",
    "\n",
    "IMAGES_PATH = \"Tensorflow/workspace/images/collectedimages\"\n",
    "TRAIN_PATH = \"Tensorflow/workspace/images/train\"\n",
    "TEST_PATH = \"Tensorflow/workspace/images/test\"\n",
    "\n",
    "# Ensure train and test directories exist\n",
    "os.makedirs(TRAIN_PATH, exist_ok=True)\n",
    "os.makedirs(TEST_PATH, exist_ok=True)\n",
    "\n",
    "# Get list of all image files\n",
    "files = [f for f in os.listdir(IMAGES_PATH) if f.endswith('.jpg')]\n",
    "\n",
    "# Group files by label\n",
    "label_dict = {}\n",
    "for file in files:\n",
    "    label = file.split('.')[0]\n",
    "    if label not in label_dict:\n",
    "        label_dict[label] = []\n",
    "    label_dict[label].append(file)\n",
    "\n",
    "# Shuffle and split files by label\n",
    "train_files = []\n",
    "test_files = []\n",
    "\n",
    "for label, file_list in label_dict.items():\n",
    "    random.shuffle(file_list)\n",
    "    num_train = math.floor(len(file_list) * 0.8)\n",
    "    train_files.extend(file_list[:num_train])\n",
    "    test_files.extend(file_list[num_train:])\n",
    "\n",
    "# Function to copy files to their respective directories\n",
    "def copy_files(file_list, destination_path):\n",
    "    for file in file_list:\n",
    "        base_filename = os.path.splitext(file)[0]\n",
    "        # Copy image file\n",
    "        shutil.copy(os.path.join(IMAGES_PATH, file), destination_path)\n",
    "        # Copy corresponding XML file\n",
    "        shutil.copy(os.path.join(IMAGES_PATH, base_filename + '.xml'), destination_path)\n",
    "\n",
    "# Copy train files\n",
    "copy_files(train_files, TRAIN_PATH)\n",
    "\n",
    "# Copy test files\n",
    "copy_files(test_files, TEST_PATH)\n",
    "\n",
    "print(f\"Train and test datasets created. {len(train_files)} images in the train set and {len(test_files)} images in the test set.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
